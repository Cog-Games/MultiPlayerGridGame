{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Data Aggregate Analysis\n",
    "\n",
    "This notebook:\n",
    "- Loads all Excel files in `data/` matching `experiment_data_*.xlsx`.\n",
    "- Removes duplicate rows by `trialIndex` within each file and combines them.\n",
    "- Groups by `experimentType` (from experiment data) to compute collaboration success rate.\n",
    "- Loads and aggregates Questionnaire data, and plots answer distributions by RL type.\n",
    "\n",
    "Notes:\n",
    "- Expected sheets: `Experiment Data`, `Questionnaire Data`.\n",
    "- Success column: `collaborationSucceeded` (boolean or 0/1).\n",
    "- RL type column: `rlAgentType` (values like `individual`, `joint`).\n",
    "- Columns may vary; this notebook handles missing columns gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports & setup\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 180)\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "EXCEL_GLOB = 'experiment_data_*.xlsx'\n",
    "SAVE_COMBINED_CSV = True\n",
    "COMBINED_EXPERIMENT_CSV = DATA_DIR / 'combined_experiment_data.csv'\n",
    "COMBINED_QUESTIONNAIRE_CSV = DATA_DIR / 'combined_questionnaire_data.csv'\n",
    "\n",
    "excel_paths = sorted([p for p in DATA_DIR.glob(EXCEL_GLOB) if not p.name.startswith('~$')])\n",
    "len(excel_paths), excel_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def file_id_from_path(p: Path) -> str:\n",
    "    return p.stem\n",
    "\n",
    "def load_experiment_data_one_file(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read 'Experiment Data' sheet, add file columns, drop duplicates by trialIndex.\n",
    "    Returns empty DataFrame if sheet missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        xls = pd.ExcelFile(p)\n",
    "    except Exception as e:\n",
    "        print(f'[WARN] Failed to open {p.name}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sheet = None\n",
    "    for candidate in ['Experiment Data', 'experiment data', 'ExperimentData', 'Data']:\n",
    "        if candidate in xls.sheet_names:\n",
    "            sheet = candidate\n",
    "            break\n",
    "    if sheet is None:\n",
    "        print(f'[INFO] No Experiment Data sheet in {p.name}. Found: {xls.sheet_names}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(p, sheet_name=sheet)\n",
    "    except Exception as e:\n",
    "        print(f'[WARN] Failed to read {sheet} from {p.name}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Normalize columns\n",
    "    if 'trialIndex' not in df.columns:\n",
    "        # Try common variants\n",
    "        for alt in ['trial_index', 'trial', 'trialId']:\n",
    "            if alt in df.columns:\n",
    "                df = df.rename(columns={alt: 'trialIndex'})\n",
    "                break\n",
    "    if 'experimentType' not in df.columns:\n",
    "        for alt in ['experiment_type', 'experiment']:\n",
    "            if alt in df.columns:\n",
    "                df = df.rename(columns={alt: 'experimentType'})\n",
    "                break\n",
    "    if 'collaborationSucceeded' not in df.columns:\n",
    "        for alt in ['collaboration_success', 'success', 'collabSuccess']:\n",
    "            if alt in df.columns:\n",
    "                df = df.rename(columns={alt: 'collaborationSucceeded'})\n",
    "                break\n",
    "\n",
    "    # Drop duplicate trials within file\n",
    "    if 'trialIndex' in df.columns:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=['trialIndex'], keep='last')\n",
    "        after = len(df)\n",
    "        if after < before:\n",
    "            print(f'[INFO] {p.name}: dropped {before - after} duplicate trials by trialIndex')\n",
    "    else:\n",
    "        print(f'[INFO] {p.name}: missing trialIndex; no de-duplication applied')\n",
    "\n",
    "    df['source_file'] = p.name\n",
    "    df['file_id'] = file_id_from_path(p)\n",
    "    return df\n",
    "\n",
    "def load_questionnaire_one_file(p: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read 'Questionnaire Data' if present and add file columns.\n",
    "    Returns empty DataFrame if sheet missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        xls = pd.ExcelFile(p)\n",
    "    except Exception as e:\n",
    "        print(f'[WARN] Failed to open {p.name}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    qsheet = None\n",
    "    for candidate in ['Questionnaire Data', 'questionnaire data', 'Questionnaire', 'Survey']:\n",
    "        if candidate in xls.sheet_names:\n",
    "            qsheet = candidate\n",
    "            break\n",
    "    if qsheet is None:\n",
    "        # Not all files have questionnaire\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        qdf = pd.read_excel(p, sheet_name=qsheet)\n",
    "    except Exception as e:\n",
    "        print(f'[WARN] Failed to read {qsheet} from {p.name}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    qdf['source_file'] = p.name\n",
    "    qdf['file_id'] = file_id_from_path(p)\n",
    "    return qdf\n",
    "\n",
    "def mode_or_first(series: pd.Series):\n",
    "    if series is None or series.empty:\n",
    "        return np.nan\n",
    "    try:\n",
    "        m = series.mode(dropna=True)\n",
    "        return m.iloc[0] if not m.empty else series.dropna().iloc[0] if series.dropna().shape[0] else np.nan\n",
    "    except Exception:\n",
    "        return series.dropna().iloc[0] if series.dropna().shape[0] else np.nan\n",
    "\n",
    "def bool_to_int(s: pd.Series) -> pd.Series:\n",
    "    if s.dtype == bool:\n",
    "        return s.astype(int)\n",
    "    # try to coerce truthy strings\n",
    "    return s.replace({'true': 1, 'false': 0, 'True': 1, 'False': 0}).astype(float, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined experiment rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and combine experiment data\n",
    "exp_frames = []\n",
    "for p in excel_paths:\n",
    "    df = load_experiment_data_one_file(p)\n",
    "    if not df.empty:\n",
    "        exp_frames.append(df)\n",
    "\n",
    "combined_exp = pd.concat(exp_frames, ignore_index=True) if exp_frames else pd.DataFrame()\n",
    "print('Combined experiment rows:', len(combined_exp))\n",
    "if not combined_exp.empty:\n",
    "    # Normalize types\n",
    "    if 'collaborationSucceeded' in combined_exp.columns:\n",
    "        combined_exp['collaborationSucceeded'] = bool_to_int(combined_exp['collaborationSucceeded']).astype(float)\n",
    "    if 'trialIndex' in combined_exp.columns:\n",
    "        combined_exp['trialIndex'] = pd.to_numeric(combined_exp['trialIndex'], errors='coerce')\n",
    "    if SAVE_COMBINED_CSV:\n",
    "        combined_exp.to_csv(COMBINED_EXPERIMENT_CSV, index=False)\n",
    "        print(f'Saved combined experiment data -> {COMBINED_EXPERIMENT_CSV}')\n",
    "combined_exp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No experiment data found.\n"
     ]
    }
   ],
   "source": [
    "# Success rate by experimentType\n",
    "if combined_exp.empty:\n",
    "    print('No experiment data found.')\n",
    "else:\n",
    "    needed = {'experimentType', 'collaborationSucceeded'}\n",
    "    if not needed.issubset(set(combined_exp.columns)):\n",
    "        print(f'Missing columns for success rate: {needed - set(combined_exp.columns)}')\n",
    "    else:\n",
    "        grp = combined_exp.groupby('experimentType')['collaborationSucceeded'].agg(['count','sum','mean']).reset_index()\n",
    "        grp['success_rate_percent'] = (grp['mean'] * 100).round(1)\n",
    "        display(grp.sort_values('success_rate_percent', ascending=False))\n",
    "\n",
    "        plt.figure(figsize=(7,4))\n",
    "        order = grp.sort_values('success_rate_percent', ascending=False)['experimentType']\n",
    "        sns.barplot(data=grp, x='experimentType', y='success_rate_percent', order=order, color='#4C78A8')\n",
    "        plt.ylabel('Success Rate (%)')\n",
    "        plt.xlabel('Experiment Type')\n",
    "        plt.title('Collaboration Success Rate by Experiment Type')\n",
    "        for i, v in enumerate(grp.set_index('experimentType').loc[order]['success_rate_percent']):\n",
    "            plt.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined questionnaire rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and combine questionnaire data\n",
    "q_frames = []\n",
    "for p in excel_paths:\n",
    "    qdf = load_questionnaire_one_file(p)\n",
    "    if not qdf.empty:\n",
    "        q_frames.append(qdf)\n",
    "\n",
    "combined_q = pd.concat(q_frames, ignore_index=True) if q_frames else pd.DataFrame()\n",
    "print('Combined questionnaire rows:', len(combined_q))\n",
    "if not combined_q.empty and SAVE_COMBINED_CSV:\n",
    "    combined_q.to_csv(COMBINED_QUESTIONNAIRE_CSV, index=False)\n",
    "    print(f'Saved combined questionnaire data -> {COMBINED_QUESTIONNAIRE_CSV}')\n",
    "combined_q.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip merge: missing questionnaire or experiment data\n"
     ]
    }
   ],
   "source": [
    "# Merge questionnaire with per-file RL type and experimentType from experiment data\n",
    "if combined_q.empty or combined_exp.empty:\n",
    "    print('Skip merge: missing questionnaire or experiment data')\n",
    "else:\n",
    "    per_file = combined_exp.groupby('file_id').agg({\n",
    "        'rlAgentType': mode_or_first,\n",
    "        'experimentType': mode_or_first\n",
    "    }).reset_index().rename(columns={'rlAgentType': 'rl_type'})\n",
    "\n",
    "    q_merged = combined_q.merge(per_file, on='file_id', how='left')\n",
    "    print('Questionnaire merged shape:', q_merged.shape)\n",
    "    display(q_merged.head(3))\n",
    "\n",
    "    # Cache for later cells\n",
    "    questionnaire_merged = q_merged.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No merged questionnaire to plot.\n"
     ]
    }
   ],
   "source": [
    "# Plot: Play-again distribution by RL type (if available)\n",
    "if 'questionnaire_merged' not in globals():\n",
    "    print('No merged questionnaire to plot.')\n",
    "else:\n",
    "    q = questionnaire_merged.copy()\n",
    "    # Try to find a 'play again' like column\n",
    "    play_cols = [c for c in q.columns if c.lower().replace(' ', '').startswith('playagain')]\n",
    "    if not play_cols:\n",
    "        # common variants\n",
    "        for cand in ['play_again', 'Would you play again?']:\n",
    "            if cand in q.columns:\n",
    "                play_cols = [cand]\n",
    "                break\n",
    "    if not play_cols:\n",
    "        print('No play-again column found in questionnaire. Available columns example:', list(q.columns)[:20])\n",
    "    else:\n",
    "        col = play_cols[0]\n",
    "        print('Using play-again column:', col)\n",
    "        # Keep order if Likert-like values exist\n",
    "        order = [\n",
    "            'Definitely play again', 'Probably play again',\n",
    "            'Might or might not', 'Probably not', 'Definitely not'\n",
    "        ]\n",
    "        # Aggregate counts\n",
    "        agg = q.groupby(['rl_type', col], observed=True).size().reset_index(name='count')\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.barplot(data=agg, x=col, y='count', hue='rl_type', hue_order=['individual','joint'] if 'individual' in agg['rl_type'].unique() else None, order=order if set(order).intersection(set(agg[col].astype(str))) else None)\n",
    "        plt.xticks(rotation=20, ha='right')\n",
    "        plt.title('Play-again responses by RL type')\n",
    "        plt.xlabel('Response')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(title='RL Type')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: AI detection and collaboration rating plots if present\n",
    "if 'questionnaire_merged' in globals():\n",
    "    q = questionnaire_merged.copy()\n",
    "    for target_col, title in [\n",
    "        ('ai_detection', 'AI-likeness by RL type'),\n",
    "        ('collaboration_rating', 'Collaboration rating by RL type')\n",
    "    ]:\n",
    "        if target_col in q.columns:\n",
    "            agg = q.groupby(['rl_type', target_col], observed=True).size().reset_index(name='count')\n",
    "            plt.figure(figsize=(8,4))\n",
    "            sns.barplot(data=agg, x=target_col, y='count', hue='rl_type', hue_order=['individual','joint'] if 'individual' in agg['rl_type'].unique() else None)\n",
    "            plt.xticks(rotation=20, ha='right')\n",
    "            plt.title(title)\n",
    "            plt.xlabel('Response')\n",
    "            plt.ylabel('Count')\n",
    "            plt.legend(title='RL Type')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f'Skip plot: {target_col} not found in questionnaire columns')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
