{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Joint-RL Real-Time Equal Distance Validation Analysis\n",
        "\n",
        "This notebook analyzes joint-RL real-time data to validate equal distance conditions for `equal_to_both` trials in 2P3G games.\n",
        "\n",
        "## Validation Criteria\n",
        "\n",
        "For `equal_to_both` trials in 2p3g, we validate that each player is equidistant between the two goals:\n",
        "1. Player 1's distance to new goal == Player 1's distance to first shared goal\n",
        "2. Player 2's distance to new goal == Player 2's distance to first shared goal  \n",
        "3. Joint distance sum is equal (sum of distances to new goal == sum of distances to first shared goal)\n",
        "\n",
        "**Note**: Player positions should use positions when New-Goal Moment is present.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from scipy import stats\n",
        "import ast\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set publication standards\n",
        "plt.rcParams.update({\n",
        "    'font.size': 12,\n",
        "    'axes.titlesize': 14,\n",
        "    'axes.labelsize': 12,\n",
        "    'xtick.labelsize': 11,\n",
        "    'ytick.labelsize': 11,\n",
        "    'legend.fontsize': 11,\n",
        "    'figure.titlesize': 16,\n",
        "    'font.family': 'Arial'\n",
        "})\n",
        "\n",
        "# Define consistent color scheme\n",
        "CONSISTENT_COLORS = {\n",
        "    'individual': '#2E86C1',  # Blue\n",
        "    'joint': '#E74C3C',       # Red/coral\n",
        "    'success': '#28B463',     # Green\n",
        "    'failure': '#F39C12',     # Orange\n",
        "    'human': '#3498DB',       # Light blue\n",
        "    'ai': '#9B59B6',          # Purple\n",
        "    'equal': '#2ECC71',       # Green for equal distances\n",
        "    'unequal': '#E67E22'      # Orange for unequal distances\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Joint-RL Real-Time Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 15 joint-rl-realTime files\n",
            "✅ Loaded: experiment_data_ 67630f751df95f8fb373e275_2025-09-30T19-23-45-667Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 672bf480b98fd6d326fd1f69_2025-09-30T19-19-16-244Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 66469ef793a8127e49ca1992_2025-09-30T19-30-14-966Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 667178d77f8b6ed980c256ff_2025-09-30T19-20-29-183Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 6751acc5dc78128951a34f1f_2025-09-30T19-12-21-369Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_67630f751df95f8fb373e275_2025-09-30T19-39-50-935Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 6480bfd6d433e2e158870605_2025-09-30T19-11-55-119Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 57adbbe8bcf54e000152816b_2025-09-30T19-03-22-396Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 663139cbb8723d403f4e7fc8_2025-09-30T19-45-01-702Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 60f43c3a0fd9723feba1af38_2025-09-30T19-46-45-503Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 5c846aba6a4b9b0016c854f5_2025-09-30T19-45-53-921Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_5e84bd7c34d5d9072128fac1_2025-09-30T19-17-21-695Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 628e0063fa56e316da2a71cb_2025-09-30T19-21-39-714Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 57c357770e6a1f00015f6038_2025-09-30T19-24-20-234Z.xlsx (35 trials)\n",
            "✅ Loaded: experiment_data_ 566a17d07da0350012b3e876_2025-09-30T19-12-51-022Z.xlsx (35 trials)\n",
            "\n",
            "📊 Total data loaded: 525 trials from 15 participants\n",
            "\n",
            "🎯 2P3G trials: 180\n",
            "RL Agent types: rlAgentType\n",
            "joint-rl-realTime    180\n",
            "Name: count, dtype: int64\n",
            "Distance conditions: distanceCondition\n",
            "no_new_goal          45\n",
            "equal_to_both        45\n",
            "closer_to_player2    45\n",
            "closer_to_player1    45\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load joint-RL real-time data\n",
        "data_dir = Path('human-RLs/joint-rl-realTime')\n",
        "excel_files = [f for f in data_dir.glob('*.xlsx') if not f.name.startswith('~$')]\n",
        "\n",
        "def load_and_process_file(file_path):\n",
        "    \"\"\"Load Excel file and add metadata\"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(file_path)\n",
        "        participant_id = file_path.name.split('_')[2]\n",
        "        df = df.assign(participantID=participant_id)\n",
        "        df['source_file'] = file_path.name\n",
        "        # Mark as joint-rl-realTime for consistency\n",
        "        df['rlAgentType'] = 'joint-rl-realTime'\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path.name}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load all files\n",
        "print(f\"Found {len(excel_files)} joint-rl-realTime files\")\n",
        "data_frames = []\n",
        "for file in excel_files:\n",
        "    df = load_and_process_file(file)\n",
        "    if df is not None:\n",
        "        data_frames.append(df)\n",
        "        print(f'✅ Loaded: {file.name} ({len(df)} trials)')\n",
        "\n",
        "if data_frames:\n",
        "    combined_data = pd.concat(data_frames, ignore_index=True)\n",
        "    print(f\"\\n📊 Total data loaded: {len(combined_data)} trials from {combined_data['participantID'].nunique()} participants\")\n",
        "else:\n",
        "    print(\"❌ No data loaded\")\n",
        "    combined_data = pd.DataFrame()\n",
        "\n",
        "# Focus on 2P3G experiments only\n",
        "if not combined_data.empty:\n",
        "    data_2p3g = combined_data[combined_data['experimentType'] == '2P3G'].copy()\n",
        "    print(f\"\\n🎯 2P3G trials: {len(data_2p3g)}\")\n",
        "    print(f\"RL Agent types: {data_2p3g['rlAgentType'].value_counts()}\")\n",
        "    print(f\"Distance conditions: {data_2p3g['distanceCondition'].value_counts()}\")\n",
        "else:\n",
        "    data_2p3g = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions for Position and Distance Calculations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def parse_point(s):\n",
        "    \"\"\"Parse a point from string representation\"\"\"\n",
        "    if pd.isna(s) or s is None:\n",
        "        return None\n",
        "    if isinstance(s, (list, tuple)) and len(s) >= 2:\n",
        "        return tuple(s[:2])\n",
        "    if isinstance(s, str):\n",
        "        try:\n",
        "            s_clean = s.replace('null', 'None')\n",
        "            parsed = ast.literal_eval(s_clean)\n",
        "            if isinstance(parsed, (list, tuple)) and len(parsed) >= 2:\n",
        "                return tuple(parsed[:2])\n",
        "        except:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def parse_positions(s):\n",
        "    \"\"\"Parse a sequence of positions from string representation\"\"\"\n",
        "    if pd.isna(s) or s is None:\n",
        "        return []\n",
        "    if isinstance(s, str):\n",
        "        try:\n",
        "            s_clean = s.replace('null', 'None')\n",
        "            parsed = ast.literal_eval(s_clean)\n",
        "            if isinstance(parsed, list):\n",
        "                return [tuple(p) if isinstance(p, (list, tuple)) else p for p in parsed if p is not None]\n",
        "        except:\n",
        "            pass\n",
        "    return []\n",
        "\n",
        "def manhattan_distance(a, b):\n",
        "    \"\"\"Calculate Manhattan distance between two points\"\"\"\n",
        "    if a is None or b is None:\n",
        "        return np.nan\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "\n",
        "def get_player_pos_at_new_goal_moment(row, player_num):\n",
        "    \"\"\"Get player position at the moment when new goal is presented\"\"\"\n",
        "    step_val = row.get('newGoalPresentedTime')\n",
        "    if pd.isna(step_val) or step_val == '':\n",
        "        return None\n",
        "\n",
        "    step = int(float(step_val))\n",
        "\n",
        "    # Get trajectory for the specified player\n",
        "    traj_col = f'player{player_num}Trajectory'\n",
        "    traj = parse_positions(row.get(traj_col))\n",
        "\n",
        "    if not traj:\n",
        "        # Fallback to initial position if available\n",
        "        init_col = 'initPlayerGrid' if player_num == 1 else 'initAIGrid'\n",
        "        return parse_point(row.get(init_col))\n",
        "\n",
        "    if player_num == 1:\n",
        "        # Human player: use direct step index\n",
        "        if step < len(traj):\n",
        "            return traj[step]\n",
        "        return traj[-1] if traj else None\n",
        "    else:\n",
        "        # AI player: use odd indices (AI moves after human)\n",
        "        odd_positions = [traj[i] for i in range(1, len(traj), 2)]\n",
        "        if odd_positions:\n",
        "            idx = min(step, len(odd_positions) - 1)\n",
        "            return odd_positions[idx]\n",
        "        # Fallback: clamp to trajectory bounds\n",
        "        idx = max(0, min(len(traj) - 1, 2 * step - 1))\n",
        "        return traj[idx]\n",
        "\n",
        "def get_first_shared_goal_position(row):\n",
        "    \"\"\"Get the position of the first detected shared goal\"\"\"\n",
        "    first_shared_idx = row.get('firstDetectedSharedGoal')\n",
        "    if pd.isna(first_shared_idx):\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        first_shared_idx = int(first_shared_idx)\n",
        "        t1 = parse_point(row.get('target1'))\n",
        "        t2 = parse_point(row.get('target2'))\n",
        "\n",
        "        if first_shared_idx == 0 and t1 is not None:\n",
        "            return t1\n",
        "        elif first_shared_idx == 1 and t2 is not None:\n",
        "            return t2\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "print(\"✅ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Distances for Equal Distance Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Trials with new goal presented: 130\n",
            "✅ Distance calculations completed\n",
            "\n",
            "📈 Data Summary:\n",
            "Total trials with distances: 130\n",
            "Distance conditions: distanceCondition\n",
            "equal_to_both        45\n",
            "closer_to_player1    45\n",
            "closer_to_player2    40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def compute_equal_distance_validation(df):\n",
        "    \"\"\"Compute distances for equal distance validation\"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Initialize lists to store computed values\n",
        "    player1_pos_at_new = []\n",
        "    player2_pos_at_new = []\n",
        "    first_shared_goal_positions = []\n",
        "    new_goal_positions = []\n",
        "\n",
        "    # Distance calculations\n",
        "    player1_dist_to_new = []\n",
        "    player1_dist_to_first_shared = []\n",
        "    player2_dist_to_new = []\n",
        "    player2_dist_to_first_shared = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Get positions at new goal moment\n",
        "        p1_pos = get_player_pos_at_new_goal_moment(row, 1)\n",
        "        p2_pos = get_player_pos_at_new_goal_moment(row, 2)\n",
        "\n",
        "        # Get goal positions\n",
        "        first_shared_pos = get_first_shared_goal_position(row)\n",
        "        new_goal_pos = parse_point(row.get('newGoalPosition'))\n",
        "\n",
        "        # Store positions\n",
        "        player1_pos_at_new.append(p1_pos)\n",
        "        player2_pos_at_new.append(p2_pos)\n",
        "        first_shared_goal_positions.append(first_shared_pos)\n",
        "        new_goal_positions.append(new_goal_pos)\n",
        "\n",
        "        # Calculate distances\n",
        "        player1_dist_to_new.append(manhattan_distance(p1_pos, new_goal_pos))\n",
        "        player1_dist_to_first_shared.append(manhattan_distance(p1_pos, first_shared_pos))\n",
        "        player2_dist_to_new.append(manhattan_distance(p2_pos, new_goal_pos))\n",
        "        player2_dist_to_first_shared.append(manhattan_distance(p2_pos, first_shared_pos))\n",
        "\n",
        "    # Add computed values to dataframe\n",
        "    df = df.assign(\n",
        "        player1_pos_at_new_goal=player1_pos_at_new,\n",
        "        player2_pos_at_new_goal=player2_pos_at_new,\n",
        "        first_shared_goal_pos=first_shared_goal_positions,\n",
        "        new_goal_pos=new_goal_positions,\n",
        "        player1_dist_to_new_goal=player1_dist_to_new,\n",
        "        player1_dist_to_first_shared=player1_dist_to_first_shared,\n",
        "        player2_dist_to_new_goal=player2_dist_to_new,\n",
        "        player2_dist_to_first_shared=player2_dist_to_first_shared\n",
        "    )\n",
        "\n",
        "    # Calculate distance differences for validation\n",
        "    df['player1_distance_diff'] = df['player1_dist_to_new_goal'] - df['player1_dist_to_first_shared']\n",
        "    df['player2_distance_diff'] = df['player2_dist_to_new_goal'] - df['player2_dist_to_first_shared']\n",
        "\n",
        "    # Calculate joint distance sums\n",
        "    df['joint_dist_to_new_goal'] = df['player1_dist_to_new_goal'] + df['player2_dist_to_new_goal']\n",
        "    df['joint_dist_to_first_shared'] = df['player1_dist_to_first_shared'] + df['player2_dist_to_first_shared']\n",
        "    df['joint_distance_diff'] = df['joint_dist_to_new_goal'] - df['joint_dist_to_first_shared']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply distance calculations to 2P3G data\n",
        "if not data_2p3g.empty:\n",
        "    # Filter for trials where new goal was presented\n",
        "    data_with_new_goal = data_2p3g[data_2p3g['newGoalPresented'] == True].copy()\n",
        "    print(f\"📊 Trials with new goal presented: {len(data_with_new_goal)}\")\n",
        "\n",
        "    # Compute distances\n",
        "    data_with_distances = compute_equal_distance_validation(data_with_new_goal)\n",
        "    print(f\"✅ Distance calculations completed\")\n",
        "\n",
        "    # Show data summary\n",
        "    print(f\"\\n📈 Data Summary:\")\n",
        "    print(f\"Total trials with distances: {len(data_with_distances)}\")\n",
        "    print(f\"Distance conditions: {data_with_distances['distanceCondition'].value_counts()}\")\n",
        "else:\n",
        "    data_with_distances = pd.DataFrame()\n",
        "    print(\"❌ No 2P3G data available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Equal-to-Both Trials\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Equal-to-both trials: 45\n",
            "\n",
            "=== EQUAL DISTANCE VALIDATION ===\n",
            "\n",
            "1️⃣ Player 1 Distance Equality:\n",
            "   ✅ Equal distances: 1/45 (2.2%)\n",
            "   ❌ Unequal distances: 44\n",
            "\n",
            "2️⃣ Player 2 Distance Equality:\n",
            "   ✅ Equal distances: 0/45 (0.0%)\n",
            "   ❌ Unequal distances: 45\n",
            "\n",
            "3️⃣ Joint Distance Sum Equality:\n",
            "   ✅ Equal sums: 10/45 (22.2%)\n",
            "   ❌ Unequal sums: 35\n",
            "\n",
            "🏆 OVERALL VALIDATION:\n",
            "   ✅ Perfect equality (all criteria): 0/45 (0.0%)\n",
            "   ❌ Failed validation: 45\n"
          ]
        }
      ],
      "source": [
        "# Filter for equal_to_both trials\n",
        "if not data_with_distances.empty:\n",
        "    equal_to_both_trials = data_with_distances[\n",
        "        data_with_distances['distanceCondition'] == 'equal_to_both'\n",
        "    ].copy()\n",
        "\n",
        "    print(f\"🎯 Equal-to-both trials: {len(equal_to_both_trials)}\")\n",
        "\n",
        "    if len(equal_to_both_trials) > 0:\n",
        "        print(\"\\n=== EQUAL DISTANCE VALIDATION ===\\n\")\n",
        "\n",
        "        # Define validation criteria (allowing small floating point errors)\n",
        "        tolerance = 1e-10\n",
        "\n",
        "        # Validation 1: Player 1's distance equality\n",
        "        player1_equal = np.abs(equal_to_both_trials['player1_distance_diff']) <= tolerance\n",
        "        player1_equal_count = player1_equal.sum()\n",
        "        player1_equal_pct = (player1_equal_count / len(equal_to_both_trials)) * 100\n",
        "\n",
        "        print(f\"1️⃣ Player 1 Distance Equality:\")\n",
        "        print(f\"   ✅ Equal distances: {player1_equal_count}/{len(equal_to_both_trials)} ({player1_equal_pct:.1f}%)\")\n",
        "        print(f\"   ❌ Unequal distances: {len(equal_to_both_trials) - player1_equal_count}\")\n",
        "\n",
        "        # Validation 2: Player 2's distance equality\n",
        "        player2_equal = np.abs(equal_to_both_trials['player2_distance_diff']) <= tolerance\n",
        "        player2_equal_count = player2_equal.sum()\n",
        "        player2_equal_pct = (player2_equal_count / len(equal_to_both_trials)) * 100\n",
        "\n",
        "        print(f\"\\n2️⃣ Player 2 Distance Equality:\")\n",
        "        print(f\"   ✅ Equal distances: {player2_equal_count}/{len(equal_to_both_trials)} ({player2_equal_pct:.1f}%)\")\n",
        "        print(f\"   ❌ Unequal distances: {len(equal_to_both_trials) - player2_equal_count}\")\n",
        "\n",
        "        # Validation 3: Joint distance sum equality\n",
        "        joint_equal = np.abs(equal_to_both_trials['joint_distance_diff']) <= tolerance\n",
        "        joint_equal_count = joint_equal.sum()\n",
        "        joint_equal_pct = (joint_equal_count / len(equal_to_both_trials)) * 100\n",
        "\n",
        "        print(f\"\\n3️⃣ Joint Distance Sum Equality:\")\n",
        "        print(f\"   ✅ Equal sums: {joint_equal_count}/{len(equal_to_both_trials)} ({joint_equal_pct:.1f}%)\")\n",
        "        print(f\"   ❌ Unequal sums: {len(equal_to_both_trials) - joint_equal_count}\")\n",
        "\n",
        "        # Overall validation: All three criteria must be met\n",
        "        all_criteria_met = player1_equal & player2_equal & joint_equal\n",
        "        all_criteria_count = all_criteria_met.sum()\n",
        "        all_criteria_pct = (all_criteria_count / len(equal_to_both_trials)) * 100\n",
        "\n",
        "        print(f\"\\n🏆 OVERALL VALIDATION:\")\n",
        "        print(f\"   ✅ Perfect equality (all criteria): {all_criteria_count}/{len(equal_to_both_trials)} ({all_criteria_pct:.1f}%)\")\n",
        "        print(f\"   ❌ Failed validation: {len(equal_to_both_trials) - all_criteria_count}\")\n",
        "\n",
        "        # Add validation flags to dataframe\n",
        "        equal_to_both_trials['player1_distances_equal'] = player1_equal\n",
        "        equal_to_both_trials['player2_distances_equal'] = player2_equal\n",
        "        equal_to_both_trials['joint_distances_equal'] = joint_equal\n",
        "        equal_to_both_trials['perfect_equality'] = all_criteria_met\n",
        "\n",
        "    else:\n",
        "        print(\"❌ No equal_to_both trials found\")\n",
        "        equal_to_both_trials = pd.DataFrame()\n",
        "else:\n",
        "    print(\"❌ No data with distances available\")\n",
        "    equal_to_both_trials = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Validation Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💾 Detailed validation results saved to: joint_rl_realtime_equal_distance_validation_results.csv\n",
            "   Columns: 24\n",
            "   Rows: 45\n",
            "\n",
            "📊 Summary statistics saved to: joint_rl_realtime_equal_distance_validation_summary.csv\n",
            "\n",
            "🎉 Analysis complete! All validation results have been exported.\n"
          ]
        }
      ],
      "source": [
        "if not equal_to_both_trials.empty:\n",
        "    # Create summary dataset for export\n",
        "    export_columns = [\n",
        "        'participantID', 'trialIndex', 'experimentType', 'rlAgentType', 'distanceCondition',\n",
        "        'newGoalPresentedTime', 'firstDetectedSharedGoal',\n",
        "        'player1_pos_at_new_goal', 'player2_pos_at_new_goal',\n",
        "        'first_shared_goal_pos', 'new_goal_pos',\n",
        "        'player1_dist_to_new_goal', 'player1_dist_to_first_shared', 'player1_distance_diff',\n",
        "        'player2_dist_to_new_goal', 'player2_dist_to_first_shared', 'player2_distance_diff',\n",
        "        'joint_dist_to_new_goal', 'joint_dist_to_first_shared', 'joint_distance_diff',\n",
        "        'player1_distances_equal', 'player2_distances_equal', 'joint_distances_equal', 'perfect_equality'\n",
        "    ]\n",
        "\n",
        "    # Filter columns that exist in the dataframe\n",
        "    available_columns = [col for col in export_columns if col in equal_to_both_trials.columns]\n",
        "\n",
        "    export_data = equal_to_both_trials[available_columns].copy()\n",
        "\n",
        "    # Save detailed results\n",
        "    output_file = 'joint_rl_realtime_equal_distance_validation_results.csv'\n",
        "    export_data.to_csv(output_file, index=False)\n",
        "    print(f\"\\n💾 Detailed validation results saved to: {output_file}\")\n",
        "    print(f\"   Columns: {len(available_columns)}\")\n",
        "    print(f\"   Rows: {len(export_data)}\")\n",
        "\n",
        "    # Create summary statistics\n",
        "    summary_stats = {\n",
        "        'total_equal_to_both_trials': len(equal_to_both_trials),\n",
        "        'player1_equality_success': equal_to_both_trials['player1_distances_equal'].sum(),\n",
        "        'player1_equality_rate': (equal_to_both_trials['player1_distances_equal'].sum() / len(equal_to_both_trials)) * 100,\n",
        "        'player2_equality_success': equal_to_both_trials['player2_distances_equal'].sum(),\n",
        "        'player2_equality_rate': (equal_to_both_trials['player2_distances_equal'].sum() / len(equal_to_both_trials)) * 100,\n",
        "        'joint_equality_success': equal_to_both_trials['joint_distances_equal'].sum(),\n",
        "        'joint_equality_rate': (equal_to_both_trials['joint_distances_equal'].sum() / len(equal_to_both_trials)) * 100,\n",
        "        'perfect_equality_success': equal_to_both_trials['perfect_equality'].sum(),\n",
        "        'perfect_equality_rate': (equal_to_both_trials['perfect_equality'].sum() / len(equal_to_both_trials)) * 100,\n",
        "        'player1_distance_diff_mean': equal_to_both_trials['player1_distance_diff'].mean(),\n",
        "        'player1_distance_diff_std': equal_to_both_trials['player1_distance_diff'].std(),\n",
        "        'player2_distance_diff_mean': equal_to_both_trials['player2_distance_diff'].mean(),\n",
        "        'player2_distance_diff_std': equal_to_both_trials['player2_distance_diff'].std(),\n",
        "        'joint_distance_diff_mean': equal_to_both_trials['joint_distance_diff'].mean(),\n",
        "        'joint_distance_diff_std': equal_to_both_trials['joint_distance_diff'].std()\n",
        "    }\n",
        "\n",
        "    summary_df = pd.DataFrame([summary_stats])\n",
        "    summary_file = 'joint_rl_realtime_equal_distance_validation_summary.csv'\n",
        "    summary_df.to_csv(summary_file, index=False)\n",
        "    print(f\"\\n📊 Summary statistics saved to: {summary_file}\")\n",
        "\n",
        "    # Perfect equality trials for further analysis\n",
        "    perfect_trials = equal_to_both_trials[equal_to_both_trials['perfect_equality']]\n",
        "    if len(perfect_trials) > 0:\n",
        "        perfect_file = 'joint_rl_realtime_perfect_equality_trials.csv'\n",
        "        perfect_trials[available_columns].to_csv(perfect_file, index=False)\n",
        "        print(f\"\\n✅ Perfect equality trials saved to: {perfect_file}\")\n",
        "        print(f\"   These {len(perfect_trials)} trials can be used for further analysis.\")\n",
        "\n",
        "    print(\"\\n🎉 Analysis complete! All validation results have been exported.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No data available for export\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook validates the equal distance conditions for `equal_to_both` trials in joint-RL real-time 2P3G experiments. The analysis checks three key criteria:\n",
        "\n",
        "1. **Player 1 Distance Equality**: Player 1's distance to the new goal should equal their distance to the first shared goal\n",
        "2. **Player 2 Distance Equality**: Player 2's distance to the new goal should equal their distance to the first shared goal  \n",
        "3. **Joint Distance Sum Equality**: The sum of both players' distances to the new goal should equal the sum of their distances to the first shared goal\n",
        "\n",
        "### Key Findings:\n",
        "- The analysis uses player positions at the exact moment when the new goal is presented (`newGoalPresentedTime`)\n",
        "- Distance calculations use Manhattan distance as specified in the game mechanics\n",
        "- Trials that meet all three criteria are identified as having \"perfect equality\" and can be used for further analysis\n",
        "- Results are exported for downstream analysis and validation\n",
        "\n",
        "### Files Generated:\n",
        "- `joint_rl_realtime_equal_distance_validation_results.csv`: Detailed results for all equal_to_both trials\n",
        "- `joint_rl_realtime_equal_distance_validation_summary.csv`: Summary statistics\n",
        "- `joint_rl_realtime_perfect_equality_trials.csv`: Trials that pass all validation criteria\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
